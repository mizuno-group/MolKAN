{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Created by Zehao Li (Takuho Ri)**\n",
    "- **Created on 2025-02-14 (Fri)  14:57:03 (+09:00)**\n",
    "\n",
    "transform all molecule from smiles to graph (for AttentiveFP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "project_path = os.getcwd().split(\"/prep\")[0]\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.AttentiveFP.featurizer import _prep_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_dir = os.path.join(project_path, \"data\", \"tox_csv\")\n",
    "graph_dir = os.path.join(project_path, \"data\", \"AttentiveFP_graphs\")\n",
    "\n",
    "os.makedirs(graph_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare graphs except BACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== sider ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7968842e6d463698ab26efbcd3c830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1384 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:50] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:52] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:52] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:52] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:53] WARNING: not removing hydrogen atom without neighbors\n",
      "[15:35:53] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== herg_karim ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3859cff891b048be872c52fa4bab1da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13445 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== tox21_M ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101737ab2cb540519e3c57593c4b7229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7811 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:36:33] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== cyp3a4_inhib ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1af54e0a06634de99b39f58d44b70b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12319 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== cyp2c9_inhib ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5625933eaca84277823531383477b3bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12083 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== toxcast_M ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a0268875de5466488bd967417f107a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[15:37:51] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== clintox_M ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "647f0183ee0348928b8b0c2f58014a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1468 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ld50 ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd7ea2e7a7de457b8b2af5a115cf0aaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7385 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for data in os.listdir(csv_dir):\n",
    "    if data == \"bace.csv\":\n",
    "        continue\n",
    "    print(f\"=== {data.replace(\".csv\", \"\")} ===\")\n",
    "    df = pd.read_csv(os.path.join(csv_dir, data), index_col=0)\n",
    "    smiles = np.array(df[\"cano_smi\"])\n",
    "    ys = np.array(df[df.columns.values[2:]])\n",
    "    assert len(smiles) == len(ys), \"difficult length between smiles and y !\"\n",
    "    graphs = []\n",
    "    for smi, y in tqdm(zip(smiles, ys), total=len(smiles)):\n",
    "        y = torch.tensor(y).float().view(1, -1)\n",
    "        atom_feats, edge_idx, edge_feats = _prep_feats(smi)\n",
    "        graph = Data(atom_feats, edge_idx, edge_feats, y)\n",
    "        graphs.append(graph)\n",
    "    with open(os.path.join(graph_dir, f\"{data.replace(\".csv\", \".pkl\")}\"), \"wb\") as f:\n",
    "        pickle.dump(graphs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare graphs for BACE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== bace ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bf71610d3f9427db74155a4a7562185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]]) torch.Size([1, 1])\n",
      "tensor([[9.1549]]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== bace ===\")\n",
    "df = pd.read_csv(os.path.join(csv_dir, \"bace.csv\"), index_col=0)\n",
    "smiles = np.array(df[\"cano_smi\"])\n",
    "ys_c = np.array(df[[\"Class\"]])\n",
    "ys_r = np.array(df[[\"pIC50\"]])\n",
    "assert len(smiles) == len(ys_c) == len(ys_r), \"difficult length between smiles and y !\"\n",
    "graphs_c = []\n",
    "graphs_r = []\n",
    "cnt = 0\n",
    "for smi, y_c, y_r in tqdm(zip(smiles, ys_c, ys_r), total=len(smiles)):\n",
    "    y_c = torch.tensor(y_c).float().view(1, -1)\n",
    "    y_r = torch.tensor(y_r).float().view(1, -1)\n",
    "    atom_feats, edge_idx, edge_feats = _prep_feats(smi)\n",
    "    graph_c = Data(atom_feats, edge_idx, edge_feats, y_c)\n",
    "    graph_r = Data(atom_feats, edge_idx, edge_feats, y_r)\n",
    "    graphs_c.append(graph_c)\n",
    "    graphs_r.append(graph_r)\n",
    "    if cnt == 0:\n",
    "        print(y_c, y_c.shape)\n",
    "        print(y_r, y_r.shape)\n",
    "        cnt += 1\n",
    "with open(os.path.join(graph_dir, f\"bace_c.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(graphs_c, f)\n",
    "with open(os.path.join(graph_dir, f\"bace_r.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(graphs_r, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 1., nan, nan, 0., 0., 1., 0., 0., 0., 0.]]) torch.Size([1, 12])\n"
     ]
    }
   ],
   "source": [
    "with open(\"/workspace/ToxPred/MolKAN/molkan/data/AttentiveFP_graphs/tox21_M.pkl\", \"rb\") as f:\n",
    "    test = pickle.load(f)\n",
    "print(test[0].y, test[0].y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add herg small for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== herg small ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a662341776d3496a89b8c240a33e4fc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/655 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.]]) torch.Size([1, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[16:39:54] WARNING: not removing hydrogen atom without neighbors\n",
      "[16:39:54] WARNING: not removing hydrogen atom without neighbors\n"
     ]
    }
   ],
   "source": [
    "print(\"=== herg small ===\")\n",
    "df = pd.read_csv(\"/workspace/ToxPred/MolKAN/molkan/data/original_csv/TDC/Tox/herg.csv\", index_col=0)\n",
    "smiles = np.array(df[\"Drug\"])\n",
    "ys = np.array(df[[\"Y\"]])\n",
    "assert len(smiles) == len(ys), \"difficult length between smiles and y !\"\n",
    "graphs = []\n",
    "cnt = 0\n",
    "for smi, y in tqdm(zip(smiles, ys), total=len(smiles)):\n",
    "    y = torch.tensor(y).float().view(1, -1)\n",
    "    atom_feats, edge_idx, edge_feats = _prep_feats(smi)\n",
    "    graph = Data(atom_feats, edge_idx, edge_feats, y)\n",
    "    graphs.append(graph)\n",
    "    if cnt == 0:\n",
    "        print(y, y.shape)\n",
    "        cnt += 1\n",
    "with open(os.path.join(graph_dir, f\"herg_small.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(graphs, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add herg central for test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== herg small ===\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "101687b461bf49d0bfc7de44c80e48c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/306893 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.]]) torch.Size([1, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"=== herg central ===\")\n",
    "df = pd.read_csv(\"/workspace/ToxPred/MolKAN/molkan/data/original_csv/TDC/Tox/herg_central.csv\", index_col=0)\n",
    "smiles = np.array(df[\"X\"])\n",
    "ys = np.array(df[[\"hERG_inhib\"]])\n",
    "assert len(smiles) == len(ys), \"difficult length between smiles and y !\"\n",
    "graphs = []\n",
    "cnt = 0\n",
    "for smi, y in tqdm(zip(smiles, ys), total=len(smiles)):\n",
    "    y = torch.tensor(y).float().view(1, -1)\n",
    "    atom_feats, edge_idx, edge_feats = _prep_feats(smi)\n",
    "    graph = Data(atom_feats, edge_idx, edge_feats, y)\n",
    "    graphs.append(graph)\n",
    "    if cnt == 0:\n",
    "        print(y, y.shape)\n",
    "        cnt += 1\n",
    "with open(os.path.join(graph_dir, f\"herg_central.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(graphs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pip-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
